{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pacotes necessários"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import scipy\n",
    "import matplotlib \n",
    "import seaborn\n",
    "import numba\n",
    "import gmpy2\n",
    "import pysubgroup as ps\n",
    "import numpy as np\n",
    "import math\n",
    "sys.path.append('./projeto_aprendizado_descritivo')\n",
    "sys.path\n",
    "from src.util.results2folder import attach_results,print2folder\n",
    "from _classes import SSDC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leitura do banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/dengue_internacao.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecionando as colunas desejadas\n",
    "df_selecionado = df[['ano', 'data_notificacao', 'sigla_uf_notificacao', 'data_primeiros_sintomas', 'idade_paciente', \n",
    "                     'sexo_paciente', 'raca_cor_paciente', 'escolaridade_paciente', 'gestante_paciente', \n",
    "                     'possui_doenca_autoimune', 'possui_diabetes', 'possui_doencas_hematologicas', \n",
    "                     'possui_hepatopatias', 'possui_doenca_renal', 'possui_hipertensao', \n",
    "                     'possui_doenca_acido_peptica', 'apresenta_febre','apresenta_cefaleia','apresenta_exantema','apresenta_dor_costas','apresenta_mialgia','apresenta_vomito','apresenta_conjutivite','apresenta_dor_retroorbital',\n",
    "                     'apresenta_artralgia','apresenta_artrite','apresenta_leucopenia','apresenta_petequias',\n",
    "                     'data_internacao','classificacao_final','evolucao_caso', 'data_obito', 'data_encerramento']]\n",
    "\n",
    "df_selecionado = df_selecionado[df_selecionado['ano'] >= 2023]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento do banco de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformando atributo nominal data_obito para binário houve_obito\n",
    "df_selecionado['houve_obito'] = df_selecionado['data_obito'].apply(lambda x: 0 if pd.isna(x) else 1)\n",
    "\n",
    "# remoção data_obito\n",
    "df_selecionado = df_selecionado.drop(columns=['data_obito'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removendo as linhas onde não houveram datas de primeiros sintomas ou data da notificação.\n",
    "df_selecionado = df_selecionado.dropna(subset=['data_primeiros_sintomas', 'data_notificacao'])\n",
    "\n",
    "df_selecionado['data_notificacao'] = pd.to_datetime(df_selecionado['data_notificacao'], errors='coerce')\n",
    "df_selecionado['data_primeiros_sintomas'] = pd.to_datetime(df_selecionado['data_primeiros_sintomas'], errors='coerce')\n",
    "# criando a coluna 'tempo_internacao'\n",
    "df_selecionado['intervalo_busca_atendimento'] = df_selecionado.apply(\n",
    "    lambda row: (row['data_notificacao'] - row['data_primeiros_sintomas']).days if pd.notna(row['data_primeiros_sintomas']) else 0,\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removendo as linhas onde não houveram internações ou data de encerramento.\n",
    "df_selecionado = df_selecionado.dropna(subset=['data_internacao', 'data_encerramento'])\n",
    "\n",
    "# convertendo as colunas para datetime\n",
    "df_selecionado['data_encerramento'] = pd.to_datetime(df_selecionado['data_encerramento'], errors='coerce')\n",
    "df_selecionado['data_internacao'] = pd.to_datetime(df_selecionado['data_internacao'], errors='coerce')\n",
    "\n",
    "# criando a coluna 'intervalo_sintoma_internacao' que é a data dos primeiros sintomas até a data que ela foi internada.\n",
    "df_selecionado['intervalo_sintoma_internacao'] = df_selecionado.apply(\n",
    "    lambda row: (row['data_internacao'] - row['data_primeiros_sintomas']).days if pd.notna(row['data_internacao']) else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# criando a coluna 'intervalo_internacao'\n",
    "df_selecionado['intervalo_internacao'] = df_selecionado.apply(\n",
    "    lambda row: (row['data_encerramento'] - row['data_internacao']).days if pd.notna(row['data_internacao']) else 0,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "df_selecionado = df_selecionado.query(\"intervalo_internacao >= 0 and intervalo_internacao <= 90 and\" + \" intervalo_sintoma_internacao >= 0 and intervalo_sintoma_internacao <= 90 and\"\n",
    "              + \" intervalo_busca_atendimento >= 0 and intervalo_busca_atendimento <= 90\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: na variável, idade_paciente, retirar manter os valores depois de \"-\" e transformar em inteiro\n",
    "df_selecionado['idade_paciente'] = df_selecionado['idade_paciente'].str.split('-').str[1]\n",
    "df_selecionado['idade_paciente'] = df_selecionado['idade_paciente'].str.extract('(\\d+)').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop das variáveis data_notificacao, data_primeiros_sintomas, data_internacao e data_encerramento\n",
    "df_selecionado = df_selecionado.drop(['data_notificacao', 'data_primeiros_sintomas', 'data_internacao', 'data_encerramento'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# recodificando as variáveis categóricas\n",
    "raca_cor_map = {\n",
    "    1:\"Branca\",\n",
    "    2:\"Preta\",\n",
    "    3:\"Amarela\",\n",
    "    4:\"Parda\",\n",
    "    5:\"Indígena\",\n",
    "    9:\"Ignorado\"\n",
    "}\n",
    "df_selecionado[\"raca_cor_paciente\"] = df_selecionado[\"raca_cor_paciente\"].map(raca_cor_map)\n",
    "\n",
    "escolaridade_map = {\n",
    "    0: \"Analfabeto\",\n",
    "    1: \"1ª a 4ª série incompleta do EF\",\n",
    "    2: \"4ª série completa do EF\",\n",
    "    3: \"5ª A 8ª série incomplet do EF\",\n",
    "    4: \"Ensino fundamental incompleto\",\n",
    "    5: \"Ensino médio incompleto\",\n",
    "    6: \"Ensino médio completo\",\n",
    "    7: \"Educação superior incompleta\",\n",
    "    8: \"Educação superior completa\",\n",
    "    9: \"Ignorado\",\n",
    "    10: \"Não se Aplica\"\n",
    "}\n",
    "\n",
    "df_selecionado[\"escolaridade_paciente\"] = df_selecionado[\"escolaridade_paciente\"].map(escolaridade_map)\n",
    "\n",
    "gestante_map = {\n",
    "    1:\"1ºTrimestre\", 2:\"2ºTrimestre\", 3:\"3ºTrimestre\", 4:\"Idade gestacional Ignorada\", 5:\"Não\", 6:\"Não se aplica\",9:\"Ignorado\"\n",
    "}\n",
    "\n",
    "df_selecionado[\"gestante_paciente\"] = df_selecionado[\"gestante_paciente\"].map(gestante_map)\n",
    "\n",
    "dicotomia_map = {\n",
    "    1: \"Sim\",\n",
    "    2: \"Não\"\n",
    "}\n",
    "\n",
    "col_dicotomia = ['possui_doenca_autoimune', 'possui_diabetes', 'possui_doencas_hematologicas', \n",
    "                     'possui_hepatopatias', 'possui_doenca_renal', 'possui_hipertensao', \n",
    "                     'possui_doenca_acido_peptica', 'apresenta_febre','apresenta_cefaleia','apresenta_exantema','apresenta_dor_costas','apresenta_mialgia','apresenta_vomito','apresenta_conjutivite','apresenta_dor_retroorbital',\n",
    "                     'apresenta_artralgia','apresenta_artrite','apresenta_leucopenia','apresenta_petequias']\n",
    "\n",
    "for col in col_dicotomia:\n",
    "    df_selecionado[col] = df_selecionado[col].map(dicotomia_map)\n",
    "\n",
    "classificacao_map={\n",
    "    5: \"Descartado\",\n",
    "    10: \"Dengue\", \n",
    "    11: \"Dengue com Sinais de Alarme\",\n",
    "    12: \"Dengue Grave\", \n",
    "    13: \"Chikungunya\"\n",
    "}\n",
    "\n",
    "df_selecionado['classificacao_final'] = df_selecionado['classificacao_final'].map(classificacao_map).fillna(np.nan)\n",
    "\n",
    "evolucao_map={\n",
    "    1:\"Cura\",\n",
    "    2:\"Óbito pelo agravo\", \n",
    "    3:\"Óbito por outras causas\",\n",
    "    4:\"Óbito em investigação\", \n",
    "    9:\"Ignorado\",\n",
    "}\n",
    "\n",
    "df_selecionado['evolucao_caso']=df_selecionado['evolucao_caso'].map(evolucao_map).fillna(np.nan)\n",
    "df_selecionado['houve_obito'] = df_selecionado['houve_obito'].map({1: 'sim', 0: 'não'})\n",
    "\n",
    "df_selecionado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## retirando os resultados NaN do banco de dados\n",
    "df_selecionado = df_selecionado.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformar variáveis nominais em categóricas\n",
    "df_aux = df_selecionado\n",
    "categoricas_var = ['sigla_uf_notificacao','sexo_paciente','raca_cor_paciente','escolaridade_paciente','gestante_paciente','possui_doenca_autoimune', 'possui_diabetes', 'possui_doencas_hematologicas', \n",
    "                     'possui_hepatopatias', 'possui_doenca_renal', 'possui_hipertensao', \n",
    "                     'possui_doenca_acido_peptica', 'apresenta_febre','apresenta_cefaleia','apresenta_exantema','apresenta_dor_costas','apresenta_mialgia','apresenta_vomito','apresenta_conjutivite','apresenta_dor_retroorbital',\n",
    "                     'apresenta_artralgia','apresenta_artrite','apresenta_leucopenia','apresenta_petequias','classificacao_final','evolucao_caso','houve_obito']\n",
    "\n",
    "for col in categoricas_var:\n",
    "    df_selecionado[col]=pd.Categorical(df_selecionado[col])\n",
    "\n",
    "df_selecionado"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste intervalo_internacao BeamSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar banco df_selecionado\n",
    "\n",
    "data = df_selecionado\n",
    "\n",
    "\n",
    "#target = ps.BinaryTarget ('sobrevivencia', True)\n",
    "target2 = ps.NumericTarget('intervalo_internacao')\n",
    "searchspace = ps.create_selectors(data, ignore=['intervalo_internacao'])\n",
    "task = ps.SubgroupDiscoveryTask (\n",
    "    data,\n",
    "    target2,\n",
    "    searchspace,\n",
    "    result_set_size=60,\n",
    "    depth=3,\n",
    "    qf=ps.StandardQFNumeric(1.0))\n",
    "result = ps.BeamSearch(beam_width=65).execute(task)\n",
    "print(result.to_dataframe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_beam_search = result.to_dataframe()\n",
    "#Calculando o z-score do Beam Search\n",
    "def zscore(n, mu_s, mu_d, sig_d):\n",
    "    value = ((float(n)**0.5)*(float(mu_s)-mu_d))/sig_d\n",
    "    return abs(value)\n",
    "mu = result_beam_search['mean_dataset'].values[0]\n",
    "sig = result_beam_search['std_dataset'].values[0]\n",
    "result_beam_search['z-score'] = result_beam_search.apply(lambda x: zscore(x['size_sg'], x['mean_sg'], mu, sig), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste intervalo_internacao DFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar banco df_selecionado\n",
    "\n",
    "data = df_selecionado\n",
    "\n",
    "\n",
    "#target = ps.BinaryTarget ('sobrevivencia', True)\n",
    "target2 = ps.NumericTarget('intervalo_internacao')\n",
    "searchspace = ps.create_selectors(data, ignore=['intervalo_internacao'])\n",
    "task = ps.SubgroupDiscoveryTask (\n",
    "    data,\n",
    "    target2,\n",
    "    searchspace,\n",
    "    result_set_size=60,\n",
    "    depth=2,\n",
    "    qf=ps.StandardQFNumeric(1.0))\n",
    "result = ps.DFS().execute(task)\n",
    "print(result.to_dataframe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dfs=result.to_dataframe()\n",
    "#Calculando o z-score do DFS\n",
    "result_dfs['z-score'] = result_dfs.apply(lambda x: zscore(x['size_sg'], x['mean_sg'], mu, sig), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \tTeste intervalo_internação SSDC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_selecionado.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"discovery\"\n",
    "target_type = \"numeric\"\n",
    "\n",
    "# load class and fit to data\n",
    "model = SSDC(task = task_name,max_depth=3, beam_width=25,max_rules=20,n_cutpoints=3)\n",
    "model.fit(df_selecionado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model)\n",
    "pd.DataFrame(model.antecedent_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = SSDC(task = task_name, max_depth=4, beam_width=25,max_rules=20,n_cutpoints=3)\n",
    "model2.fit(df_selecionado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = SSDC(task = task_name,max_depth=3, beam_width=25,max_rules=20,n_cutpoints=5)\n",
    "model3.fit(df_selecionado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = SSDC(task = task_name,max_depth=4, beam_width=25,max_rules=20,n_cutpoints=5)\n",
    "model4.fit(df_selecionado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = SSDC(task = task_name,max_depth=3, beam_width=50,max_rules=20,n_cutpoints=3)\n",
    "model5.fit(df_selecionado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = SSDC(task = task_name,max_depth=4, beam_width=50,max_rules=20,n_cutpoints=3)\n",
    "model6.fit(df_selecionado)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estatísticas de Qualidade por modelo no SSDC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_estat = pd.DataFrame(model.statistic_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_model = pd.DataFrame(model.antecedent_description, columns=['Subgrupros'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_model = pd.concat([df_model, model_estat], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_model['z-score'] = result_model.apply(lambda x: zscore(x['usage'], x['mean'], mu, sig), axis=1)\n",
    "result_model.sort_values('z-score', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_estat2 = pd.DataFrame(model2.statistic_rules)\n",
    "df_model2 = pd.DataFrame(model2.antecedent_description, columns=['Subgrupros'])\n",
    "result_model2 = pd.concat([df_model2, model_estat2], axis=1)\n",
    "result_model2['z-score'] = result_model2.apply(lambda x: zscore(x['usage'], x['mean'], mu, sig), axis=1)\n",
    "result_model2.sort_values('z-score', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_estat3 = pd.DataFrame(model3.statistic_rules)\n",
    "df_model3 = pd.DataFrame(model3.antecedent_description, columns=['Subgrupros'])\n",
    "result_model3 = pd.concat([df_model3, model_estat3], axis=1)\n",
    "result_model3['z-score'] = result_model3.apply(lambda x: zscore(x['usage'], x['mean'], mu, sig), axis=1)\n",
    "result_model3.sort_values('z-score', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_estat4 = pd.DataFrame(model4.statistic_rules)\n",
    "df_model4 = pd.DataFrame(model4.antecedent_description, columns=['Subgrupros'])\n",
    "result_model4 = pd.concat([df_model4, model_estat4], axis=1)\n",
    "result_model4['z-score'] = result_model4.apply(lambda x: zscore(x['usage'], x['mean'], mu, sig), axis=1)\n",
    "result_model4.sort_values('z-score', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_estat5 = pd.DataFrame(model5.statistic_rules)\n",
    "df_model5 = pd.DataFrame(model5.antecedent_description, columns=['Subgrupros'])\n",
    "result_model5 = pd.concat([df_model5, model_estat5], axis=1)\n",
    "result_model5['z-score'] = result_model5.apply(lambda x: zscore(x['usage'], x['mean'], mu, sig), axis=1)\n",
    "result_model5.sort_values('z-score', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_estat6 = pd.DataFrame(model6.statistic_rules)\n",
    "df_model6 = pd.DataFrame(model6.antecedent_description, columns=['Subgrupros'])\n",
    "result_model6 = pd.concat([df_model6, model_estat6], axis=1)\n",
    "result_model6['z-score'] = result_model6.apply(lambda x: zscore(x['usage'], x['mean'], mu, sig), axis=1)\n",
    "result_model6.sort_values('z-score', ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Salvando os experimentos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experimentos = 'experimentos_sd.xlsx'\n",
    "\n",
    "with pd.ExcelWriter(experimentos) as writer:\n",
    "    result_model.to_excel(writer, sheet_name='SSD_modelo_1', index=False)\n",
    "    result_model2.to_excel(writer, sheet_name='SSD_modelo_2', index=False)\n",
    "    result_model3.to_excel(writer, sheet_name='SSD_modelo_3', index=False)\n",
    "    result_model4.to_excel(writer, sheet_name='SSD_modelo_4', index=False)\n",
    "    result_model5.to_excel(writer, sheet_name='SSD_modelo_5', index=False)\n",
    "    result_model6.to_excel(writer, sheet_name='SSD_modelo_6', index=False)\n",
    "    result_beam_search.to_excel(writer, sheet_name='Beam_Search', index=False)\n",
    "    result_dfs.to_excel(writer, sheet_name='DFS', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
